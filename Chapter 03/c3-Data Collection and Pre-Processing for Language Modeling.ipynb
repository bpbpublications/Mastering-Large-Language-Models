{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3e1bd80",
   "metadata": {},
   "source": [
    "# Data Cleaning Techniques - Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe11940",
   "metadata": {},
   "source": [
    "**Example 1: Basic Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8bdbea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "# Lowercasing\n",
    "def lowercase(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Punctuation removal\n",
    "def remove_punctuation(text):\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    return text\n",
    "\n",
    "# Removing special characters\n",
    "def remove_special_chars(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Stop words removal\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "# Text standardization\n",
    "def standardize_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    standardized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(standardized_tokens)\n",
    "\n",
    "# Spelling correction\n",
    "def correct_spelling(text):\n",
    "    corrected_text = \"\"\n",
    "    from spellchecker import SpellChecker\n",
    "    spell = SpellChecker()\n",
    "    corrected_text = ' '.join([spell.correction(word) for word in text.split()])\n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd4f5eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data cleaning techniques\n",
    "def clean_text(text):\n",
    "    cleaned_text = lowercase(text)\n",
    "    cleaned_text = remove_punctuation(cleaned_text)\n",
    "    cleaned_text = remove_special_chars(cleaned_text)\n",
    "    cleaned_text = remove_stopwords(cleaned_text)\n",
    "    cleaned_text = standardize_text(cleaned_text)\n",
    "    cleaned_text = correct_spelling(cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31833d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world example text cleaning using python\n",
      "hi im market im data scientist love working data nap large experience field\n"
     ]
    }
   ],
   "source": [
    "# Try on some of the samples\n",
    "text = \"Hello, World! This is an examplle of text cleaning using Python.\"\n",
    "cleaned_text = clean_text(text)\n",
    "print(cleaned_text)\n",
    "\n",
    "text = \"Hi! I'm Sanket and I'm a Data Scientist. I love working with #data and #NLPs. I a have large experience in this fielld.\"\n",
    "cleaned_text = clean_text(text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dec553",
   "metadata": {},
   "source": [
    "# Data Cleaning Techniques - Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6997b4e",
   "metadata": {},
   "source": [
    "**Example 2: Entity detection using spaCy library in Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f91b6ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael Jackson PERSON\n",
      "India GPE\n",
      "1996 DATE\n",
      "Mumbai GPE\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Load a pre-trained spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a sample sentence\n",
    "sentence = \"Michael Jackson came to India in 1996 for a concert in Mumbai.\"\n",
    "\n",
    "# Apply the spaCy model to the sentence\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Print the entities and their labels\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f4ba1d",
   "metadata": {},
   "source": [
    "**Example 3: Anonymization using the spaCy library in Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9543bc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON PERSON came to GPE in DATE for a concert in GPE .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define the text to be anonymized\n",
    "text = \"Michael Jackson came to India in 1996 for a concert in Mumbai.\"\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the named entities and replace them with placeholders\n",
    "anonymized_tokens = []\n",
    "for token in doc:\n",
    "    if token.ent_type_ in ['PERSON', 'GPE', 'DATE']:\n",
    "        anonymized_tokens.append(token.ent_type_)\n",
    "    else:\n",
    "        anonymized_tokens.append(token.text)\n",
    "\n",
    "# Join the anonymized tokens back into a single string\n",
    "anonymized_text = ' '.join(anonymized_tokens)\n",
    "\n",
    "# Print the anonymized text\n",
    "print(anonymized_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58e9ba59",
   "metadata": {},
   "source": [
    "# Text Pre-processing: Preparing Text for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d15b275",
   "metadata": {},
   "source": [
    "**Example 4: Text pre-processing example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecc7a23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['The', 'quick', 'brown', 'foxes', 'jumped', 'over', 'the', 'lazy', 'dogs', '.']\n",
      "Stemmed Tokens: ['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazi', 'dog', '.']\n",
      "Lemmatized Tokens: ['The', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Sample text\n",
    "text = \"The quick brown foxes jumped over the lazy dogs.\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "print(\"Stemmed Tokens:\", stemmed_tokens)\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "print(\"Lemmatized Tokens:\", lemmatized_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d933ef09",
   "metadata": {},
   "source": [
    "# Data Annotation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c3b489d",
   "metadata": {},
   "source": [
    "**Example 5: Part-of-Speech (POS) Tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffe4a7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John PROPN NNP\n",
      "wants VERB VBZ\n",
      "to PART TO\n",
      "buy VERB VB\n",
      "$ SYM $\n",
      "1 NUM CD\n",
      "million NUM CD\n",
      "house NOUN NN\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"John wants to buy $1 million house\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f47189a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun, proper singular\n",
      "verb, 3rd person singular present\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "print(spacy.explain(\"NNP\"))\n",
    "print(spacy.explain(\"VBZ\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee9e1084",
   "metadata": {},
   "source": [
    "**Example 6: Dependency parsing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40beba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanketkhandare/miniconda/envs/nlp/lib/python3.10/site-packages/spacy/displacy/__init__.py:108: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"1c1109aa41b44c51bc7204f82582865d-0\" class=\"displacy\" width=\"1625\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">John</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">saw</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">flashy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">blue</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">hat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">store</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1c1109aa41b44c51bc7204f82582865d-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1c1109aa41b44c51bc7204f82582865d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1c1109aa41b44c51bc7204f82582865d-0-1\" stroke-width=\"2px\" d=\"M420,352.0 C420,89.5 920.0,89.5 920.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1c1109aa41b44c51bc7204f82582865d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1c1109aa41b44c51bc7204f82582865d-0-2\" stroke-width=\"2px\" d=\"M595,352.0 C595,177.0 915.0,177.0 915.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1c1109aa41b44c51bc7204f82582865d-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1c1109aa41b44c51bc7204f82582865d-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1c1109aa41b44c51bc7204f82582865d-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1c1109aa41b44c51bc7204f82582865d-0-4\" stroke-width=\"2px\" d=\"M245,352.0 C245,2.0 925.0,2.0 925.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1c1109aa41b44c51bc7204f82582865d-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,354.0 L933.0,342.0 917.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1c1109aa41b44c51bc7204f82582865d-0-5\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1c1109aa41b44c51bc7204f82582865d-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1085.0,354.0 L1093.0,342.0 1077.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1c1109aa41b44c51bc7204f82582865d-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1c1109aa41b44c51bc7204f82582865d-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1c1109aa41b44c51bc7204f82582865d-0-7\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,177.0 1440.0,177.0 1440.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1c1109aa41b44c51bc7204f82582865d-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1440.0,354.0 L1448.0,342.0 1432.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5051 ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"John saw a flashy blue hat at the store\")\n",
    "displacy.serve(doc, style=\"dep\", port=5051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30515e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
